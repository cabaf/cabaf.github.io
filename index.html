<html>
<head>
<title>Fabian Caba Heilbron</title>
<style>
h1 { padding : 0; margin : 0; }
body { padding : 0; font-family : Arial; font-size : 16px;  background-color : #EFEFEF;} /* background-image : url('bg.png');}*/
#container { width : 900px; margin : 20px auto; border-radius: 20px;  background-color : #fff; padding : 50px;  box-shadow: 0px 0px 40px #666; } /* border : 1px solid #ccc; } */
#me { border : 0 solid black; margin-bottom : 50px;}
#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}
#content { display : block; }
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
a.invisible { color : inherit; text-decoration : inherit; }
.publogo { margin-right : 20px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #000; }
.publication .links { position : relative; top : 15px }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;}
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
#simpsons { margin : 5px auto; text-align : left; color : #B7B7B7; }
#erdos { color : #999; text-align : center; font-size : 12px; }
.contact { margin-left : 40px; }
.contact td { width : 300px; vertical-align : top; }
.schoollogo { text-align : center; color : #999; width : 150px;}
.schoollogo img { margin-bottom : 10px; }
</style>
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-56208223-1', 'auto');
  ga('send', 'pageview');

</script>

</head>
<body>
<div id="container">
<div id="content">
<div itemscope itemtype="http://data-vocabulary.org/Person">
<h1><span itemprop="name">Fabian Caba Heilbron</span></h1>

<div id="sidebar">
<img src="img/fabian.png" id="me" width="180" itemprop="photo" class="img-circle">
</div>

<p> I am a Ph.D. candidate at <a href="http://www.kaust.edu.sa/">KAUST</a> advised by Professor <a href="http://www.bernardghanem.com/">Bernard Ghanem</a>. I was fortunate to work with <a href="http://www.niebles.net/">Juan Carlos Niebles</a> during my master studies at Universidad del Norte.</p>

<p>My research interests span computer vision and machine learning. Specifically, I build systems that <b>recognize and detect human activities from videos</b>. Some of my efforts include:
</p>
<ul>
<li> gathering large-scale video <b>datasets</b></li>
<li> developing <b>efficient scanning methods</b> for video analysis</li>
<li> training models for <b>temporal activity localization</b></li>
</ul>

<!--<p> I was fortunate to work with <a href="http://www.niebles.net/">Juan Carlos Niebles</a> during my master studies. </p>-->

<p> If you want to reach out, please <b>contact me at:</b> fabian.caba [at] kaust.edu.sa </p>

</div>

<h2>Professional Experience</h2>
<p><b>IVUL [2015-Present]:</b> I am a Research Assistant at <a href="https://ivul.kaust.edu.sa/Pages/Home.aspx" target="_blank">IVUL</a>. My work focuses on developing models for human activity understanding. The outcomes of my works are usually published at computer vision conferences (<a href="#publications-div">see Publications</a>).

<p><b>ActivityNet Challenge [2016-Present]:</b> I am one of the leading forces behind organizing the <a href="http://activity-net.org/challenges/2018" target="_blank">ActivityNet Challenge</a>. I built the infrastructure that allows multiple researchers to test-bed their methods. The challenge has attracted a large number of researchers, and it has been sponsored by several companies including DeepMind, Facebook, and Google AI.</p> 

<p><b>Mantis AI [2017-Present]:</b> I am a co-founder of <a href="http://mantis-ai.com/" target="_blank">Mantis AI</a>. Mantis crafts ground-breaking research in deep-learning to perform activity detection and video summarization for content-aware ad placement.</p>

<p><b>Adobe Research [Summer 2017, Summer 2018]:</b> I was an intern for two consecutive summers at Adobe Research. During these periods I developed: (i) an active learning method for action detection; (ii) a navigation system for video editing purposes.</p>
<h2 id="publications-div">Publications</h2>

<div class="publication"><a href="https://cabaf.github.io/what-to-annotate-next/"><img src="https://ivul.kaust.edu.sa/PublishingImages/Publications/2018/main/What%20do%20I%20Annotate%20Next%20An%20Empirical%20Study%20of%20Active%20Learning%20for%20Action%20Localization.jpg" class="publogo" width="228" height="120"></a>
<br>
<strong><a href="https://cabaf.github.io/what-to-annotate-next/">What do I Annotate Next? An Empirical Study of <br> Active Learning for Action Localization</a></strong><br>
<b>Fabian Caba Heilbron</b>, Joon-Young Lee, Hailin Jin, Bernard Ghanem</br>  
<em>Munich, ECCV 2018. - </em>
[<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Fabian_Caba_What_do_I_ECCV_2018_paper.pdf">Paper</a>]
[<a href="https://cabaf.github.io/what-to-annotate-next/">Project page</a>]
</span>
</div>
</br>
</br>

<div class="publication"><a href="http://humamalwassel.com/publication/action-search/"><img src="http://humamalwassel.com/img/headers/action-search.gif" class="publogo" width="228" height="70"></a>
<strong><a href="http://humamalwassel.com/publication/action-search/">Action Search: Spotting Targets in Videos and Its Application to <br> Temporal Action Localization</a></strong><br>
Humam Alwassel*, <b>Fabian Caba Heilbron*</b>, Bernard Ghanem; 
<em> * := equal contribution</em></br>
<em>Munich, ECCV 2018. - </em>
[<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Humam_Alwassel_Action_Search_Spotting_ECCV_2018_paper.pdf">Paper</a>]
[<a href="http://humamalwassel.com/publication/action-search/">Project page</a>]
[<a href="https://www.youtube.com/watch?v=HHGoz4Y5QzM">Video</a>]
</span>
</div>
</br>

<div class="publication"><a href="http://humamalwassel.com/publication/detad/"><img src="http://humamalwassel.com/img/headers/detad.jpg" class="publogo" width="228" height=70></a>
<strong><a href="http://humamalwassel.com/publication/detad/">Diagnosing Error in Temporal Action Detectors</a></strong><br>
Humam Alwassel*, <b>Fabian Caba Heilbron*</b>, Victor Escorcia*, Bernard Ghanem<br>
<em> * := equal contribution</em></br>
<em>Munich, ECCV 2018. - </em>
[<a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Humam_Alwassel_Diagnosing_Error_in_ECCV_2018_paper.pdf">Paper</a>]
[<a href="http://humamalwassel.com/publication/detad/">Project page</a>]
[<a href="https://github.com/HumamAlwassel/DETAD">Code (Github)</a>]
[<a href="https://www.youtube.com/watch?v=rnndiuF2ouM">Video</a>]
</span>
</div>
</br>

<div class="publication"><a href="https://ivul.kaust.edu.sa/Pages/pub-scc-efficient-action-detection.aspx"><img src="img/scc.png" class="publogo" width="228" height="85"></a>
<br>
<strong><a href="https://ivul.kaust.edu.sa/Pages/pub-scc-efficient-action-detection.aspx">SCC: Semantic Context Cascade for Efficient Action Detection</a></strong><br>
<b>Fabian Caba Heilbron</b>, Wayner Barrios, Victor Escorcia, Bernard Ghanem<br>
<em>Hawaii, CVPR 2017. - </em>
[<a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Heilbron_SCC_Semantic_Context_CVPR_2017_paper.pdf">Paper</a>]
[<a href="https://drive.google.com/open?id=0B9WpeMTDrC3fbDY2cHh4TWViX0U">Poster</a>]
</span>
</div>

</br>

<div class="publication">
<a href="https://ivul.kaust.edu.sa/Pages/pub-Daps.aspx"><img src="http://escorciav.github.io/img/portfolio/kaust16_modal.png" class="publogo" width="228" height="85"></a>
<br>
<strong><a href="https://ivul.kaust.edu.sa/Pages/pub-Daps.aspx">DAPs: Deep Action Proposals for Action Understanding</a></strong><br>
Victor Escorcia, <b>Fabian Caba Heilbron</b>, Juan Carlos Niebles, Bernard Ghanem<br>
<em>Amsterdam, ECCV 2016. - </em>
[<a href="https://drive.google.com/open?id=0B0ZXjo_p8lHBcjh1WDlmYVN3R2M">Paper</a>]
[<a href="https://github.com/escorciav/daps">Code (Github)</a>]
[<a href="http://www.eccv2016.org/files/posters/P-2B-10.pdf">Poster</a>]
</span>
</div>

</br>
</br>

<div class="publication">
<a href="temporalproposals/index.html"><img src="img/proposals.png" class="publogo" width="228" height="85"></a>
<strong><a href="temporalproposals/index.html">Fast Temporal Activity Proposals for <br> Efficient Detection of Human Actions in Untrimmed Videos</a></strong><br>
<b>Fabian Caba Heilbron</b>, Juan Carlos Niebles, Bernard Ghanem<br>
<em>Las Vegas, CVPR 2016. - </em>
[<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Heilbron_Fast_Temporal_Activity_CVPR_2016_paper.pdf">Paper</a>]
[<a href="temporalproposals/index.html">Project page</a>]
[<a href="https://github.com/cabaf/sparseprop">Code (Github)</a>]
[<a href="temporalproposals/demo.html">Demo</a>]
</span>
</div>

</br>

<div class="publication">
<a href="http://activity-net.org/"><img src="img/anet.png" class="publogo" width="228" height="55"></a>
<strong><a href="http://activity-net.org/">ActivityNet: A Large-Scale Video Benchmark for Human Activity Understanding</a></strong><br>
<b>Fabian Caba Heilbron</b>, Victor Escorcia, Bernard Ghanem, Juan Carlos Niebles<br>
<em>Boston, CVPR 2015. - </em>
[<a href="https://dl.dropboxusercontent.com/u/18955644/website_files/ActivityNet/ActivityNet_CVPR2015.pdf">Paper</a>]
[<a href="http://activity-net.org/">Project page</a>]
[<a href="https://github.com/activitynet/ActivityNet">Code (Github)</a>]
[<a href="http://activity-net.org/explore.html">Demo</a>]
</span>
</div>

</br>

<div class="publication">
<a href="https://ivul.kaust.edu.sa/Pages/Pub-Manhattan-Frame-Estimation-CVPR-2015.aspx"><img src="img/manhatan.png" class="publogo" width="228" height="90"></a>
<strong><a href="https://ivul.kaust.edu.sa/Pages/Pub-Manhattan-Frame-Estimation-CVPR-2015.aspx">Robust Manhattan Frame Estimation from a Single RGB-D Image
</a></strong><br>
Bernard Ghanem, Ali Thabet, Juan Carlos Niebles, <b>Fabian Caba Heilbron</b><br>
<em>Boston, CVPR 2015. - </em>
[<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Ghanem_Robust_Manhattan_Frame_2015_CVPR_paper.pdf">Paper</a>]
[<a href="https://ivul.kaust.edu.sa/Pages/Pub-Manhattan-Frame-Estimation-CVPR-2015.aspx">Project page</a>]
[<a href="https://ivul.kaust.edu.sa/Documents/more/code/MFE.zip">Code</a>]
[<a href="https://ivul.kaust.edu.sa/Documents/Data/Robust%20Manhattan%20Frame%20Estimation%20from%20a%20Single%20RGB-D%20Image.zip">Data</a>]
</span>
</div>

</br>
</br>

<div class="publication">
<a href="actioncue/index.html"><img src="img/actioncue.png" class="publogo" width="228" height="90"></a>
<strong><a href="actioncue/index.html">Camera Motion and Surrounding Scene Appearance as Context for Action Recognition</a></strong><br>
<b>Fabian Caba Heilbron</b>, Ali Thabet, Juan Carlos Niebles, Bernard Ghanem<br>
<em>Singapore, ACCV 2014. - </em>
[<a href="actioncue/paper/actioncue.pdf">Paper</a>]
[<a href="actioncue/index.html">Project page</a>]</span>
<!--<a href="actioncue/poster/actioncue.pdf">Poster</a>-->
</div>

</br>

<div class="publication" style="margin-top: 20px;">
<a href="http://yamdrok.stanford.edu/crowd/icmr.pdf"><img src="img/crowd.png" class="publogo" width="228" height="80"></a>
<strong><a href="http://yamdrok.stanford.edu/crowd/icmr.pdf">Collecting and Annotating Human Activities in Web Videos</a></strong><br>
<b>Fabian Caba Heilbron</b>, Juan Carlos Niebles<br>
<em>Glasgow, ICMR 2014. - </em>
[<a href="http://yamdrok.stanford.edu/crowd/icmr.pdf">Paper</a>]
[<a href="https://github.com/cabaf/activity_annotation">Code (Github)</a>]
</span>
<!--<a href="#">Poster</a> </br></span>-->
</div>

<!--
<h2>Thesis</h2>

<div class="publication">
<a href="mthesis.pdf"><img src="thesis.png" class="publogo"></a>
<p><strong><a href="#">Retrieving, Annotating and Recognizing Human Activities in Web Videos</a></strong><br>
Fabian Caba<br>
<em>M.S. Thesis, Universidad del Norte, 2013</em><br>
<span class="links"><a href="#">Thesis</a> </span>
</p>
</div>
-->
<p style="margin-top:50px;text-align:center;font-size:16px;padding-top:20px;">In God we trust. All others must bring data.<br>&mdash; <a href="http://en.wikipedia.org/wiki/W._Edwards_Deming">W. Edwards Deming</a></p>

</div>
</div>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
</body>
</html>
